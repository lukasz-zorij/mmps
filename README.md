# Multi-Model Prompt Synthesis (MMPS)

Date : 09/20/2024 |
Author : Lukasz Zorij (em b64 - bHVrYXN6QHpvcmlsbGEuZXU= ) |
(EN : Wookash Zoreey)

![LZ Logo](image/lz-logo.png)

# Introduction

In this research, the utilization of dual models is employed to strike a balance between generating diverse ideas through a simpler model and applying sophisticated reasoning and refinement via an advanced model. This approach first and foremost enhances the quality of the output and is also cost-effective. The meticulous preparation of the initial input prompt significantly influences the quality of the final response, as detailed instructions are provided to the model. This methodology allows for the transformation of simple ideas or problems into more sophisticated solutions. The user's initial prompt undergoes analysis and is deconstructed into atomic-level keywords. The most pertinent information is extracted and elaborated upon using model instructions, which occurs prior to generating the final response. The correlation of keywords and their pairings offers additional context and significantly impacts the comprehensive description of each element of the user's input. The final responses from each iteration are scored on a scale of 1 to 10, with scores generated by a more advanced model. Ultimately, the optimal response is both scored and generated by this sophisticated model.

The most important part is to formulate the initial user's prompt using a concise description of the goal, preferred tools (such as libraries and methodology), and desired outcomes. This solution handles the rest.

This framework opens avenues for experimentation and allows the manipulation of various models, parameters, such as the number of iterations, key word count, feedback regression, temperature, and the number of tokens, number of layers, among others.


![MMPS](image/MMPS.svg)
*Diagram showing step by step synthesis.*
# Advantages

This approach offers several notable benefits, which can be systematically utilized in the following ways:

- **Diverse Initial Answers:** Initial responses are generated by the simpler model, ensuring a wide range of possibilities are explored.
- **Structured Improvement:** Through detailed, step-by-step reasoning, these initial ideas undergo structured enhancement.
- **Multiple Layers of Refinement:** The iterative process allows for multiple layers of refinement, honing the responses to a higher degree of accuracy and sophistication.
- **Objective Evaluation:** Each answer is objectively evaluated, ensuring that the most promising solutions are identified and further developed.
- **Synthesis of Optimal Elements:** The best aspects of each response are synthesized into a comprehensive final answer, capitalizing on the strengths of the dual-model approach.
- **Advanced Problem Solving:** The simpler model is leveraged to solve complex problems in an advanced manner when provided with detailed, step-by-step instructions as the initial input.

For example, consider the prompt: "Write a function in Python to simulate a reverb effect using all parameters. Ensure the code follows best practices. The input is a 16-bit, 44.1 kHz, stereo wave file." This task benefits from the outlined advantages, enhancing the generation of a refined and effective solution.
# Logic

The proposed methodology follows a structured approach to decompose and systematically process user prompts to derive comprehensive solutions. This logic involves several layers, each uniquely contributing to the refinement and enhancement of the solution:

1. **Main Prompt Example:**
   - Initial prompt: "Write a reverb function in Python."
   - Key objective: Extract and analyze key components to develop a robust solution.

2. **Layered Prompt Processing:**
   - **Layer 1:** Utilizes a cost-effective model, such as the GPT-4o-mini variant, to extract essential keywords or phrases from the user's input and provide concise descriptions for each.
     - Example Prompt: "Given the user's input: '{user_prompt}', extract 5 keywords or phrases and provide a one-sentence description for each."
     - Outputs: Keywords stored for subsequent analysis.

   - **Layer 2:** Analyzes the relationship between each keyword and the problem at hand, leveraging the same model.
     - Example Prompt: "User's input: '{user_prompt}'. Analyze each keyword: {keywords}. Explain how it relates to solving the problem."
     - Outputs: Analytical insights stored for further processing.

   - **Layer 3:** Generates correlations between keywords, detailing their combined impact on the problem.
     - Example Prompt: "Based on user's input: '{user_prompt}', create pairs of keywords from the analyses: {analyses}. Explain how each pair relates to the problem."
     - Outputs: Keyword pair correlations.

   - **Layer 4:** Synthesizes and integrates the findings from Layer 3 with additional contextual insights into a cohesive narrative.
     - Example Prompt: "Taking into account the user's input: '{user_prompt}', synthesize and mix the following correlations into a unified explanation: {correlations}. Do not include any code just information on how to solve the problem."
     - Outputs: Synthesized response.

   - **Layer 5:** Combines the outputs from Layers 3 and 4, consolidating them into a final, comprehensive response using the latest GPT-4o model.
     - Example Prompt: "With the user's input in mind: '{user_prompt}', summarize the following information into a final, comprehensive response: {combined}. Do not include any code just information on how to solve the problem."
     - Outputs: Final synthesized responses.

3. **Iterative Processing:**
   - The main loop is executed three (3) times, adjusting the temperature (+0.2) and maximum token limits (+200) at each iteration to enhance creativity and response quality.

4. **Advanced Scoring Mechanism:**
   - Utilizes an advanced model to score responses from each loop on a scale of 1-10, ensuring objectivity and precision.
     - Example Prompt: "Use scoring technique from 1-10 (Output only score, no comments) to evaluate the following responses: User's input: '{user_prompt}' {combined_responses}"
     - Outputs: Best-ranked solution is selected for the final implementation prompt.

5. **Optimal Solution Prompting:**
   - Example Final Prompt: "Do not simplify anything; it is a waste of time. Compare with original functionality. Use exactly how and what is in these instructions and requirements to implement it in the best way, fully working solution: """{best_answer}"""

The described logic supports extracting maximum value from each prompt iteration, efficiently driving towards an optimized and thoroughly analyzed solution.
## Below is the pseudo code representation of the described logic, written in a pythonic style:

Pseudo-code implementation:

 ```python
def process_user_prompt(user_prompt):
    """
    Processes the user prompt through several layers to generate a comprehensive solution.

    Parameters:
    - user_prompt: A string representing the user's initial request.

    Returns:
    - best_answer: The best-scored response after processing the prompt.
    """
    # Define initial system prompt and parameters
    system_prompt = "You are an expert in solving problems and analysis."
    temperature = 0.3
    max_tokens = 100
    final_tokens = 2000  # Set the maximum length of the final response
    iteration_count = 3

    # Initialize memory storage for different processing stages
    memory = {
        'keywords': [],
        'analyses': [],
        'correlations': [],
        'syntheses': [],
        'responses': []
    }

    # Main processing loop
    for iteration in range(iteration_count):
        print(f"Iteration {iteration + 1}/{iteration_count}: Starting processing loop.")

        # Layer 1: Keyword Extraction
        keywords = extract_keywords(user_prompt)
        memory['keywords'].extend(keywords)
        print(f"Layer 1: Extracted keywords: {keywords}")

        # Layer 2: Keyword Analysis
        analyses = analyze_keywords(memory['keywords'])
        memory['analyses'].extend(analyses)
        print(f"Layer 2: Analyzed keywords: {analyses}")

        # Layer 3: Keyword Correlation
        correlations = correlate_keywords(memory['analyses'])
        memory['correlations'].extend(correlations)
        print(f"Layer 3: Correlated keywords into pairs: {correlations}")

        # Layer 4: Synthesis Using All Combinations of Pairs
        synthesis = synthesize_correlations(memory['correlations'])
        memory['syntheses'].append(synthesis)
        print(f"Layer 4: Synthesized insights from all combinations of pairs: {synthesis}")

        # Layer 5: Final Synthesis and Response
        response = summarize_final_response(user_prompt, memory['correlations'], memory['syntheses'], final_tokens)
        memory['responses'].append(response)
        print(f"Layer 5: Summarized final response: {response}")

        # Adjust parameters for the next iteration
        temperature += 0.2
        max_tokens += 200
        print(f"Adjusted parameters - Temperature: {temperature}, Max Tokens: {max_tokens}")

    # Scoring and selection of the best response
    best_answer = score_responses(memory['responses'])
    print(f"Best scored response: {best_answer}")

    return best_answer

def extract_keywords(prompt):
    """
    Extract keywords from the prompt.

    Parameters:
    - prompt: The user prompt.

    Returns:
    - A list of extracted keywords.
    """
    # Implement keyword extraction logic here
    keywords = ["function", "Python", "reverb"]  # Example extracted keywords
    return keywords

def analyze_keywords(keywords):
    """
    Analyze the extracted keywords to understand their relevance.

    Parameters:
    - keywords: A list of extracted keywords.

    Returns:
    - A list of analyses of the keywords.
    """
    # Implement keyword analysis logic here
    analyses = ["task focus", "language choice", "sound effect type"]  # Example analyses
    return analyses

def correlate_keywords(analyses):
    """
    Create correlations between all possible combinations of keyword analyses.

    Parameters:
    - analyses: A list of keyword analyses.

    Returns:
    - A list of keyword correlations.
    """
    # Implement correlation logic using all possible combinations here
    correlations = ["function-Python", "function-reverb", "Python-reverb"]  # Example correlations
    return correlations

def synthesize_correlations(correlations):
    """
    Synthesize correlations into cohesive insights using all combinations of pairs.

    Parameters:
    - correlations: A list of keyword correlations.

    Returns:
    - A synthesized version of the correlations.
    """
    # Implement synthesis logic using all possible pair combinations here
    pair_combinations = [f"{c1}-{c2}" for i, c1 in enumerate(correlations) for j, c2 in enumerate(correlations) if i < j]
    synthesis = f"Synthesize insights from pairs: {pair_combinations}"  # Example synthesis
    return synthesis

def summarize_final_response(prompt, correlations, syntheses, final_tokens):
    """
    Summarize and combine syntheses with all correlation combinations into a final comprehensive response.

    Parameters:
    - prompt: The user prompt.
    - correlations: A list of keyword correlations.
    - syntheses: A list of synthesized insights.
    - final_tokens: The maximum length of the final response.

    Returns:
    - The final comprehensive response.
    """
    # Implement final synthesis and summarization logic here
    final_response = "Explain how to implement the reverb function in Python, integrating all elements."[:final_tokens]  # Example final response controlling length
    return final_response

def score_responses(responses):
    """
    Score the responses to determine the best solution.

    Parameters:
    - responses: A list of synthesized responses.

    Returns:
    - The response with the best score.
    """
    # Implement scoring logic here
    best_scored_response = responses[0]  # Assuming the first one is the best for illustration
    return best_scored_response
```

### Key Components of the Pseudo-Code:

1. **Initialization:**
   - **System Prompt:** Set as "You are an expert in solving problems and analysis." to guide the model's approach.
   - **Parameters:** Initialize `temperature` to 0.3, `max_tokens` to 100, and `final_tokens` to 2000 to manage the processing style and constraints.
   - **Memory Storage:** Set up dictionaries to store intermediate results across different layers: keywords, analyses, correlations, syntheses, and responses.

2. **Main Processing Loop (Iterative Enhancements):**
   - **Iterations:** Conducted three times to refine responses through layered processing.
   - **Layer 1 (Keyword Extraction):** Extract significant keywords from the user's prompt to serve as foundational elements for further analysis.
   - **Layer 2 (Keyword Analysis):** Analyze the keywords to assess their relationship and relevance to solving the problem at hand.
   - **Layer 3 (Keyword Correlation):** Generate all possible correlations between analyzed keywords to explore their combined impacts.
   - **Layer 4 (Synthesis Using All Combinations of Pairs):** Synthesize insights from all possible combinations of keyword pairs, providing a broad perspective on potential interactions.
   - **Layer 5 (Final Synthesis and Response):** Summarize the syntheses and correlations into a comprehensive response, ensuring the length does not exceed `final_tokens`.

3. **Parameter Adjustment:**
   - Adjust `temperature` and `max_tokens` after each iteration, enhancing the creativity and complexity of responses in a controlled manner.

4. **Advanced Scoring Mechanism:**
   - Evaluate and score each synthesized response to identify the best solution using a hypothetical scoring mechanism, potentially based on predefined criteria such as relevance, completeness, and coherence.

5. **Final Output:**
   - Return the best-scored response as the optimal solution based on the iterative processing and thorough analysis, ensuring a comprehensive approach to fulfilling the user's request.

This structured framework in the pseudo-code ensures the processing is systematic and thorough, with each step building on the previous ones to derive a well-considered, detailed solution that aligns with the user's initial prompt.
# Example output from the implemented solution:

### GPT4o-mini model

***Input user's prompt : "Write reverb effect in python use 16-bit 44.1kHz stereo as input wave file."***

Final prompt (combined instruction and best answer) : 

```text
Use instructions and requirements to solve the problem or implement it in the best way - step by step, create fully working solution, generate pseudo-code for your own use to cover all requirements as a draft: 
"""To simulate a reverb effect in Python using a 16-bit, 44.1kHz, stereo WAV file, you will need to follow a structured approach that incorporates both audio processing techniques and best coding practices. Below is a unified explanation of how to approach this problem, focusing on key considerations and methodologies.

### Understanding Reverb Effect

1. **Reverb Effect - Audio Enhancement**:
   - Reverb simulates the natural echo and reflections that occur in a physical space, thus adding depth and richness to audio signals. It can be thought of as a series of delayed copies of the original sound, blended with the original signal. The goal is to create a sense of space and immersion in the audio experience.

### Working with Audio Signals

2. **Audio Signal - WAV File**:
   - The input to your function will be a stereo WAV file. This format is well-suited for audio processing because it offers high fidelity and is widely supported. You must read and manipulate the audio data from this file, ensuring that you maintain the integrity of the original signal.

### Implementation Steps

#### 1. **Reading WAV Files**:
   - Use a library such as `scipy.io.wavfile` or `wave` to read the WAV file. This will allow you to extract the sample rate and audio data. Make sure to handle stereo data appropriately, as you will be working with two channels (left and right).

#### 2. **Applying the Reverb Effect**:
   - **Delay and Decay**: Implement a series of delayed copies of the original signal with decreasing amplitude to simulate the reflections. This can be done using convolution with an impulse response that represents the reverb characteristics.
   - **Comb Filters and All-Pass Filters**: Use these filters to create the necessary reflections and diffusions. Comb filters create the initial echoes, while all-pass filters help in spreading the sound more evenly.
   - **Wet/Dry Mix**: Blend the processed (wet) signal with the original (dry) signal to control the intensity of the reverb effect.

#### 3. **Handling Stereo Channels**:
   - Process each channel (left and right) separately to maintain the stereo effect. Ensure that the reverb characteristics are consistent across both channels to avoid phase issues.

#### 4. **Writing the Processed Audio**:
   - Use the same library you used for reading the WAV file to write the processed audio data back to a new WAV file. Ensure that the output file maintains the same format (16-bit, 44.1kHz, stereo).

### Best Practices

- **Modular Code**: Break down the function into smaller, reusable components (e.g., reading the file, applying reverb, writing the file).
- **Error Handling**: Include error handling to manage issues such as file not found, incorrect file format, or read/write errors.
- **Documentation**: Comment your code and provide documentation for each function to explain its purpose and usage.
- **Testing**: Test your function with various audio files to ensure it works correctly and produces the desired reverb effect.

By following these steps and best practices, you can effectively simulate a reverb effect in Python, enhancing the audio experience of a 16-bit, 44.1kHz, stereo WAV file."""
```
#### Model first shot response :

```
To implement a reverb effect on a stereo WAV file in Python, we will follow the structured approach outlined in your instructions. Below is a step-by-step breakdown of the implementation, including pseudo-code and detailed code comments.

### Step-by-Step Approach

#### Step 1: Read the WAV File

We'll use the `scipy.io.wavfile` module to read the WAV file data. This will yield the sample rate and the audio data itself.

#### Step 2: Apply the Reverb Effect

For the reverb effect, we will implement a simple delay-based approach with a decay factor. This will create the repeated echo effect.

#### Step 3: Handle Stereo Channels

We'll process each channel separately to maintain stereo integrity.

#### Step 4: Write the Output WAV File

Finally, we will write the processed audio data back to a new WAV file using the same library.

### Pseudo-Code

plaintext

Copy Code

```plaintext
function main(input_file, output_file):
    sample_rate, audio_data = read_wav(input_file)
    processed_audio = apply_reverb(audio_data, sample_rate, delay_time=0.1, decay=0.5)
    write_wav(output_file, sample_rate, processed_audio)

function read_wav(filename):
    # Import scipy.io.wavfile
    # Read the WAV file, return sample_rate and audio_data

function apply_reverb(audio_data, sample_rate, delay_time, decay):
    # Calculate delay in samples
    delay_samples = int(delay_time * sample_rate)
    reverb_signal = create_empty_array_like(audio_data)

    # Loop through each sample of audio data
    for each sample_index in range(length(audio_data)):
        # Apply decay from delayed audio based on decay factor
        if sample_index >= delay_samples:
            reverb_signal[sample_index] += (audio_data[sample_index - delay_samples] * decay)
    
    # Combine the original audio with the reverb
    output_signal = audio_data + reverb_signal
    return normalize(output_signal)

function write_wav(filename, sample_rate, audio_data):
    # Import scipy.io.wavfile
    # Write audio_data to a WAV file with the given sample_rate

function normalize(audio_data):
    # Normalize audio_data between -1.0 and 1.0
    # Ensure that the output is still in the appropriate range for WAV format

### Implementation in Python

Here’s the full working example in Python:

python

RunCopy Code

```python
import numpy as np
from scipy.io import wavfile

def main(input_file, output_file):
    sample_rate, audio_data = read_wav(input_file)
    processed_audio = apply_reverb(audio_data, sample_rate, delay_time=0.1, decay=0.5)
    write_wav(output_file, sample_rate, processed_audio)

def read_wav(filename):
    sample_rate, audio_data = wavfile.read(filename)
    if audio_data.ndim != 2 or audio_data.shape[1] != 2:
        raise ValueError("Input WAV must be stereo (2 channels).")
    return sample_rate, audio_data

def apply_reverb(audio_data, sample_rate, delay_time, decay):
    delay_samples = int(delay_time * sample_rate)
    reverb_signal = np.zeros_like(audio_data, dtype=np.float32)

    for sample_index in range(len(audio_data)):
        # Add decay from delayed audio based on decay factor
        if sample_index >= delay_samples:
            reverb_signal[sample_index] += audio_data[sample_index - delay_samples] * decay
    
    # Combine the original audio with the reverb
    output_signal = audio_data.astype(np.float32) + reverb_signal
    return normalize(output_signal)

def write_wav(filename, sample_rate, audio_data):
    wavfile.write(filename, sample_rate, audio_data.astype(np.int16))

def normalize(audio_data):
    max_val = np.max(np.abs(audio_data))
    if max_val > 0:
        audio_data = audio_data / max_val
    return audio_data

# Example usage
if __name__ == "__main__":
    input_wav = "input.wav"
    output_wav = "output_reverb.wav"
    main(input_wav, output_wav)

### Key Considerations

1. **Dependencies**: Ensure you have the required libraries installed. You can do this by running:
    
    ```sh
    pip install scipy numpy
    ```
    
2. **Error Handling**: The provided code includes basic error handling for input WAV file validation.
    
3. **Testing**: Test the solution with various stereo audio files to fine-tune the reverb parameters.
    

This code and structured approach will give you a strong foundation for simulating a reverb effect on stereo WAV files in Python.

USER : Are you sure?

gpt-4o-mini-2024-07-18

Yes, the provided solution outlines a step-by-step approach to simulate a reverb effect on a stereo WAV file in Python. The key functionalities include reading the WAV file, processing the audio data to apply a simple reverb effect, and writing the modified audio data back to a new WAV file.

However, let's clarify and highlight a few important details as well as improvements and considerations that may enhance the solution:

### Key Points of the Implementation

1. **WAV File Handling**: The solution utilizes `scipy.io.wavfile` to read and write audio files, which is appropriate for 16-bit WAV files.
    
2. **Reverb Simulation**: The implementation uses a simple delay-based approach to create a reverb effect. This could be further enhanced by implementing additional features like:
    
    - Multiple delays for more complex reverberation tails.
    - Adjustable decay rates for different types of reverb.
3. **Normalization**: The normalization function ensures that the output audio does not exceed the allowed range for audio samples.
    
4. **Stereo Support**: The code processes stereo audio data by checking the number of channels.
    
5. **Dependencies**: Ensure to have the correct libraries installed, as noted.
    

### Possible Improvements

1. **Advanced Reverb Techniques**: For a more realistic reverb effect, consider implementing:
    
    - **Early reflections** that simulate how sound behaves in real spaces based on geometry.
    - **Diffusion** algorithms to spread sound reflections over time.
2. **Configurable Parameters**: Allow users to configure parameters such as delay time and decay factor via arguments rather than hard coding them.
    
3. **Error Handling Enhancements**: While rudimentary error handling is provided, it may be beneficial to add more specific exceptions or warnings for different parts of the process (e.g., file not found, invalid format).
    
4. **Visualization**: Consider adding an option to visualize the original and processed audio waveforms for better analysis.
    
5. **Testing with Edge Cases**: Test the solution with edge cases such as:
    
    - Files with silence.
    - Very short audio clips.
    - Different sample rates or bit depths.

### Example Usage

To ensure that you can successfully run the code:

1. Prepare a stereo WAV file named `'input.wav'` in the same directory as the script.
2. Run the script, and it should produce an output file named `'output_reverb.wav'`.

### Conclusion

The implementation is conceptually sound and provides a good starting point for creating reverb effects using WAV files in Python. If you have any specific concerns or areas you'd like to discuss or refine further, please let me know!
```

### Claude 3.5 Sonnet model

***Input user's prompt:  "Write tetris game in python use pygame."***

```text
Final prompt (combined instruction and best answer) : 

`Do not simplify anything it is waste of time.`
`Compare with original functionality.`
`Do not explain, just generate full code in one shot.`
`Use exactly how and what is in that instructions and requirements to implement it in best way, fully working solution.`
`"""To develop a Tetris game in Python using the Pygame library, follow these steps:`

1. `**Set Up the Environment**:`
   - `Install Pygame: Ensure Pygame is installed in your Python environment (pip install pygame).`
   - `Import necessary libraries: Import Pygame and other required modules.`

2. `**Initialize Pygame**:`
   - `Initialize Pygame and set up the game window with an appropriate size for a Tetris game grid.`

3. `**Define Game Constants and Variables**:`
   - `Define constants such as screen dimensions, grid size, colors, and shapes of Tetris pieces.`
   - `Create a list of the seven Tetris shapes (I, O, T, S, Z, J, L) and their rotations.`

4. `**Create Game Functions**:`
   - `**Draw Grid**: Function to draw the game grid and update it as pieces move.`
   - `**Generate New Piece**: Function to generate a new Tetris piece at the top of the grid.`
   - `**Move Piece**: Functions to handle moving the piece left, right, down, and rotating it.`
   - `**Check Collision**: Function to check for collisions with the grid boundaries or other pieces.`
   - `**Clear Lines**: Function to check for and clear completed lines, updating the score.`
   - `**Game Over**: Function to check if new pieces can no longer be placed, indicating game over.`

5. `**Game Loop**:`
   - `Create a main game loop to handle user input, update game state, and render the screen.`
   - `Handle user inputs for moving and rotating pieces.`
   - `Update the game state by moving pieces down at regular intervals.`
   - `Check for collisions and clear lines as needed.`
   - `Render the updated game grid and pieces on the screen.`

6. `**Display and Scoring**:`
   - `Update the display to show the current score, level, and next piece.`
   - `Implement a scoring system that awards points for clearing lines and increases the level as more lines are cleared.`

7. `**End Game and Restart**:`
   - `Implement functionality to detect game over and allow the player to restart the game.`

`By following these steps, you can create a functional Tetris game using Python and Pygame. Each step involves breaking down the task into manageable functions and ensuring the game logic is correctly implemented to provide a smooth and enjoyable gameplay experience."""`
```

#### Model first shot response :

```text
Here's a full implementation of a Tetris game in Python using Pygame, based on the provided instructions:



```python
import pygame
import random

# Initialize Pygame
pygame.init()

# Screen dimensions
SCREEN_WIDTH = 800
SCREEN_HEIGHT = 600
GRID_SIZE = 30
GRID_WIDTH = 10
GRID_HEIGHT = 20

# Colors
BLACK = (0, 0, 0)
WHITE = (255, 255, 255)
CYAN = (0, 255, 255)
YELLOW = (255, 255, 0)
MAGENTA = (255, 0, 255)
RED = (255, 0, 0)
GREEN = (0, 255, 0)
BLUE = (0, 0, 255)
ORANGE = (255, 165, 0)

# Tetromino shapes
SHAPES = [
    [[1, 1, 1, 1]],
    [[1, 1], [1, 1]],
    [[1, 1, 1], [0, 1, 0]],
    [[1, 1, 0], [0, 1, 1]],
    [[0, 1, 1], [1, 1, 0]],
    [[1, 1, 1], [1, 0, 0]],
    [[1, 1, 1], [0, 0, 1]]
]

COLORS = [CYAN, YELLOW, MAGENTA, GREEN, RED, BLUE, ORANGE]

# Set up the game window
screen = pygame.display.set_mode((SCREEN_WIDTH, SCREEN_HEIGHT))
pygame.display.set_caption("Tetris")

clock = pygame.time.Clock()

def create_grid():
    return [[0 for _ in range(GRID_WIDTH)] for _ in range(GRID_HEIGHT)]

def draw_grid(grid):
    for i in range(len(grid)):
        for j in range(len(grid[i])):
            pygame.draw.rect(screen, WHITE, (j*GRID_SIZE, i*GRID_SIZE, GRID_SIZE-1, GRID_SIZE-1), 1)
            if grid[i][j] != 0:
                pygame.draw.rect(screen, COLORS[grid[i][j]-1], (j*GRID_SIZE, i*GRID_SIZE, GRID_SIZE-1, GRID_SIZE-1))

def new_piece():
    shape = random.choice(SHAPES)
    return {
        'shape': shape,
        'x': GRID_WIDTH // 2 - len(shape[0]) // 2,
        'y': 0,
        'color': COLORS[SHAPES.index(shape)]
    }

def valid_move(grid, piece, x, y):
    for i in range(len(piece['shape'])):
        for j in range(len(piece['shape'][i])):
            if piece['shape'][i][j]:
                if (x + j < 0 or x + j >= GRID_WIDTH or
                    y + i >= GRID_HEIGHT or
                    (y + i >= 0 and grid[y + i][x + j])):
                    return False
    return True

def add_to_grid(grid, piece):
    for i in range(len(piece['shape'])):
        for j in range(len(piece['shape'][i])):
            if piece['shape'][i][j]:
                grid[piece['y'] + i][piece['x'] + j] = COLORS.index(piece['color']) + 1

def clear_lines(grid):
    lines_cleared = 0
    for i in range(len(grid)-1, -1, -1):
        if all(grid[i]):
            del grid[i]
            grid.insert(0, [0 for _ in range(GRID_WIDTH)])
            lines_cleared += 1
    return lines_cleared

def rotate_piece(piece):
    return {
        'shape': list(zip(*piece['shape'][::-1])),
        'x': piece['x'],
        'y': piece['y'],
        'color': piece['color']
    }

def draw_piece(piece):
    for i in range(len(piece['shape'])):
        for j in range(len(piece['shape'][i])):
            if piece['shape'][i][j]:
                pygame.draw.rect(screen, piece['color'],
                                 ((piece['x'] + j) * GRID_SIZE,
                                  (piece['y'] + i) * GRID_SIZE,
                                  GRID_SIZE - 1, GRID_SIZE - 1))

def game_over(grid):
    return any(grid[0])

def main():
    grid = create_grid()
    current_piece = new_piece()
    next_piece = new_piece()
    score = 0
    level = 1
    fall_time = 0
    fall_speed = 0.5
    game_over_flag = False

    while not game_over_flag:
        fall_time += clock.get_rawtime()
        clock.tick()

        if fall_time / 1000 > fall_speed:
            if valid_move(grid, current_piece, current_piece['x'], current_piece['y'] + 1):
                current_piece['y'] += 1
            else:
                add_to_grid(grid, current_piece)
                lines_cleared = clear_lines(grid)
                score += lines_cleared * 100
                if lines_cleared > 0:
                    level = min(10, score // 1000 + 1)
                    fall_speed = max(0.1, 0.5 - (level - 1) * 0.05)
                current_piece = next_piece
                next_piece = new_piece()
                if not valid_move(grid, current_piece, current_piece['x'], current_piece['y']):
                    game_over_flag = True
            fall_time = 0

        for event in pygame.event.get():
            if event.type == pygame.QUIT:
                game_over_flag = True
            if event.type == pygame.KEYDOWN:
                if event.key == pygame.K_LEFT:
                    if valid_move(grid, current_piece, current_piece['x'] - 1, current_piece['y']):
                        current_piece['x'] -= 1
                if event.key == pygame.K_RIGHT:
                    if valid_move(grid, current_piece, current_piece['x'] + 1, current_piece['y']):
                        current_piece['x'] += 1
                if event.key == pygame.K_DOWN:
                    if valid_move(grid, current_piece, current_piece['x'], current_piece['y'] + 1):
                        current_piece['y'] += 1
                if event.key == pygame.K_UP:
                    rotated_piece = rotate_piece(current_piece)
                    if valid_move(grid, rotated_piece, rotated_piece['x'], rotated_piece['y']):
                        current_piece = rotated_piece

        screen.fill(BLACK)
        draw_grid(grid)
        draw_piece(current_piece)

        # Draw score and level
        font = pygame.font.Font(None, 36)
        score_text = font.render(f"Score: {score}", True, WHITE)
        level_text = font.render(f"Level: {level}", True, WHITE)
        screen.blit(score_text, (SCREEN_WIDTH - 200, 50))
        screen.blit(level_text, (SCREEN_WIDTH - 200, 100))

        # Draw next piece
        next_piece_surface = pygame.Surface((100, 100))
        next_piece_surface.fill(BLACK)
        for i in range(len(next_piece['shape'])):
            for j in range(len(next_piece['shape'][i])):
                if next_piece['shape'][i][j]:
                    pygame.draw.rect(next_piece_surface, next_piece['color'],
                                     (j * GRID_SIZE, i * GRID_SIZE, GRID_SIZE - 1, GRID_SIZE - 1))
        screen.blit(next_piece_surface, (SCREEN_WIDTH - 150, 200))

        pygame.display.flip()

    # Game over screen
    font = pygame.font.Font(None, 72)
    game_over_text = font.render("Game Over", True, WHITE)
    screen.blit(game_over_text, (SCREEN_WIDTH // 2 - game_over_text.get_width() // 2, SCREEN_HEIGHT // 2 - 100))
    pygame.display.flip()

    # Wait for user to close the window
    waiting = True
    while waiting:
        for event in pygame.event.get():
            if event.type == pygame.QUIT:
                waiting = False

    pygame.quit()

if __name__ == "__main__":
    main()


This implementation includes all the required functionality for a Tetris game, including piece movement, rotation, collision detection, line clearing, scoring, and level progression. The game continues until the player can no longer place new pieces, at which point a game over screen is displayed.


```
#### Running code : 

![tetris-01.png](image/tetris-01.png)

![tetris-01.png](image/tetris-02.png)

Second try and result :

![tetris-01.png](image/tetris-03.png)
